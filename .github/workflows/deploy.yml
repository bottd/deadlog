name: Build and Deploy

on:
  push:
    branches: [main]

  # Run every hour to check for new patches
  #  schedule:
  #    - cron: '0 * * * *'

  # Allow manual triggering
  workflow_dispatch:

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Setup pipeline
        uses: ./.github/actions/setup-pipeline
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Run type checking
        run: pnpm run check

      - name: Run lint
        run: pnpm run lint

      - name: Build scraper and generate database
        run: pnpm run build:scraper
        env:
          DATABASE_URL: file:apps/web/static/deadlog.db

      - name: Export database to SQL
        run: |
          sqlite3 apps/web/static/deadlog.db .dump > deadlog.sql
          grep -v -E "^(BEGIN|COMMIT|ROLLBACK|SAVEPOINT)" deadlog.sql > deadlog-clean.sql

      - name: Drop existing D1 tables
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: pnpm exec wrangler d1 execute deadlog --remote --file=libs/db/drop-tables.sql --config=apps/web/wrangler.toml

      - name: Import new data to D1 database
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: pnpm exec wrangler d1 execute deadlog --remote --file=deadlog-clean.sql --config=apps/web/wrangler.toml

      - name: Build web project
        run: pnpm run build
        env:
          CLOUDFLARE: true
          DATABASE_URL: file:apps/web/static/deadlog.db

      - name: Deploy to Cloudflare Workers
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: pnpm exec wrangler deploy --config=apps/web/wrangler.toml
